## API lifecycle

- APIs with superseded lifecycle are not ported.

    For example, `mutate_at` from `dplyr` is superseded by `mutate` and `across`.

- APIs with experimental lifecycle are tried to be ported.

    For example, `group_map` and related functions

## Function/Argument naming

- `.` in function/argument names are replced with `_`

    For example, `is.integer` is ported as `is_integer`. Argument `.drop` in `group_by` is replaced with `_drop`.

- `datar` specific arguments are named with `_` suffix. For example, `base0_`.

- camelCase style named functions are ported with snake_case named functions.

    For example: `getOption` to `get_option`.

## Extra arguments

In order to keep some python language features, or extend the APIs a little, a few APIs may come with extra arguments. For example, to allow people to work with 0-indexing, `base0_` argument is added to functions that involve indexing. `how_` for `drop_na` is added to allow drop rows of a data frame with `any` or `all` values of in that row.

## `tibble` vs `DataFrame`

`datar` introduced `tibble` package as well. However, unlike in R, `tidyverse`'s tibble is a different class than the `data.frame` from base R, the data frame created by `datar.tibble.tibble` is actually a pandas `DataFrame`. It's just a wrapper around the constructor.

## Data frame indexes and column names

Most APIs from tidyverse packages ignore/reset the index (row names) of data frames, so do the APIs from datar. So when selecting rows, row indices are always used. With most APIs, the indices of the data frames are dropped, so they are actually ranging from 0 to `nrow(df) - 1`.

!!! Note
    when using 1-based indexing (default), 1 selects the first row. Even though the first row shows index 0 when it's printed.

No `MultiIndex` indices/column names are supported for the APIs to select or manipulate data frames and the data frames generated by the APIs will not have `MultiIndex` indices/column names. However, since it's still pandas DataFrame, you can always do it in pandas way:

```python
df = tibble(x=1, y=2)
df2 = df >> mutate(z=f.x+f.y)
# pandas way to select
df2.iloc[0, z] # 3
# add multiindex to it:
df.columns = pd.MultiIndex.from_product([df.columns, ['C']])
```

## Nested data frames

pandas DataFrame doesn't support nested data frames. However, some R packages do, especially `tidyr`.

Here we uses fake nested data frames:

```python
>>> df = tibble(x=1, y=tibble(a=2, b=3))
>>> df
        x     y$a     y$b
  <int64> <int64> <int64>
0       1       2       3
```

Now `df` is a fake nested data frame, with an inner data frame as column `y` in `df`.

!!! Warning

    For APIs from `tidyr` that tidies nested data frames, this is fully supported, but just pay attention when you operate it in pandas way. For other APIs, this feature is still experimental.

## `list` in `R` vs `list` in `python`

R's list is actually a name-value pair container. When there is a need for it, we use python's dict instead, since python's list doesn't support names.

For example:
```python
>>> names({'a':1}, 'x')
{'x': 1}
```

## `ptypes`

Unlike some APIs from `tidyverse` packages that uses a data frame as `ptypes` tempate, here we use dtypes directly or a dict with name-dtype pairs for the columns.

## Grouped/rowwise data frame

`datar` doesn't use `pandas`' `DataFrameGroupBy`/`SeriesGroupBy` classes. Instead, we have our own `DataFrameGroupBy` class, which is actually a subclass of `DataFrame`, with 3 extra properties: `_group_data`, `_group_vars` and `_group_drop`, carring the grouping data, grouping variables/columns and whether drop the non-observable values. This is very similar to `grouped_df` from `dplyr`.

The reasons that we implement this are:

1. Pandas DataFrameGroupBy cannot handle mutilpe categorical columns as
        groupby variables with non-obserable values
2. It is very hard to retrieve group indices and data when doing apply
3. NAs unmatched in grouping variables

## `NA` caveats

- dtype

    `NA` in datar sets to `numpy.nan`, which is a float. So that it causes problems for other dtypes of data, because setting a value to NA (float) in an array with other dtype is not compatible. Unlink R, python does not have missing value type for other dtypes.

    pandas has introduced it's own `NA` and some `NA` compatible dtypes. However, `numpy` is still not aware of it, which causes problems for internal computations.

- string

    When initialize a string array intentionally: `numpy.array(['a', NA])`, the `NA` will be converted to a string `'nan'`. That may not be what we want sometimes. To avoid that, use `None` or `NULL` instead:

    ```python
    >>> numpy.array(['a', None])
    array(['a', None], dtype=object)
    ```

    Just pay attention that the dtype falls back to object.


- `NaN`

    Since `NA` is already a float, `NaN` here is equivalent to `NA`.
